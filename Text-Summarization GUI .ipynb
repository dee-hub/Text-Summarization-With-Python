{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#BEFORE THE GUI BEGAN!!!!!!!!!!!!!!!!!\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "#THERE EXISTED THIS CODE FOR TEXT SUMMARIZATION\n",
    "#############################################################\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "#Function to split text into sentences by fullstop(.)\n",
    "'''def read_article(text):\n",
    "    \n",
    "    article = text.split(\". \")\n",
    "    sentences =[]\n",
    "    \n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\",\" \").split(\" \"))\n",
    "    \n",
    "    return sentences'''\n",
    "\n",
    "# Read the text and tokenize into sentences\n",
    "def read_article(text):\n",
    "    \n",
    "    sentences =[]\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        sentence.replace(\"[^a-zA-Z0-9]\",\" \")\n",
    "\n",
    "    return sentences\n",
    "    \n",
    "\n",
    "# Create vectors and calculate cosine similarity b/w two sentences\n",
    "def sentence_similarity(sent1,sent2,stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    \n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    #build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if not w in stopwords:\n",
    "            vector1[all_words.index(w)]+=1\n",
    "    \n",
    "    #build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if not w in stopwords:\n",
    "            vector2[all_words.index(w)]+=1\n",
    "            \n",
    "    return 1-cosine_distance(vector1,vector2)\n",
    "\n",
    "# Create similarity matrix among all sentences\n",
    "def build_similarity_matrix(sentences,stop_words):\n",
    "    #create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences),len(sentences)))\n",
    "    \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1!=idx2:\n",
    "                similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1],sentences[idx2],stop_words)\n",
    "                \n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "# Generate and return text summary\n",
    "def generate_summary(text,top_n):\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "    \n",
    "    # Step1: read text and tokenize\n",
    "    sentences = read_article(text)\n",
    "    \n",
    "    # Steo2: generate similarity matrix across sentences\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences,stop_words)\n",
    "    \n",
    "    # Step3: Rank sentences in similarirty matrix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "    \n",
    "    #Step4: sort the rank and place top sentences\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)),reverse=True)\n",
    "    \n",
    "    # Step 5: get the top n number of sentences based on rank    \n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(ranked_sentences[i][1])\n",
    "    \n",
    "    # Step 6 : output the summarized version\n",
    "    return \" \".join(summarize_text)\n",
    "\n",
    "############################################################################################\n",
    "#On this note we ended the long line of code responsible for Text Summarization\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "#Before we move on, let us initialize codes for our keywords extraction too\n",
    "############################################################################################\n",
    "def extract(top_n, nr_candidates, doc):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    n_gram_range = (1, 1)\n",
    "    stop_words = \"english\"\n",
    "\n",
    "    # Extract candidate words/phrases\n",
    "    count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "    candidates = count.get_feature_names()\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "    doc_embedding = model.encode([doc])\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    top_n = 10\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "        # Calculate distances and extract keywords\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, candidate_embeddings)\n",
    "\n",
    "    # Get top_n words as candidates based on cosine similarity\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # Calculate the combination of words that are the least similar to each other\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]\n",
    "\n",
    "###########################################################################################################################\n",
    "#Keywords Extraction Done\n",
    "###########################################################################################################################\n",
    "\n",
    "import tkinter as tk\n",
    "import center_tk_window\n",
    "import tkinter.font as TkFont\n",
    "from tkinter import scrolledtext\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "win = tk.Tk()\n",
    "#win.configure(background='black')\n",
    "win.geometry(\"1300x650\")\n",
    "#win.configure(bg='gr)\n",
    "win.title('Text Summarization and Keyword Extraction')\n",
    "win.resizable(False, False)\n",
    "center_tk_window.center_on_screen(win)\n",
    "font = (\"Helvetica\", 10)\n",
    "font2 = (\"Segoe Boot Semilight\", 7)\n",
    "\n",
    "helv36 = TkFont.Font(family=\"Helvetica\",size=36,weight=\"bold\")\n",
    "\n",
    "\n",
    "Frame1 = tk.Frame(win, width=1300, height=30, bg='white')\n",
    "Frame1.grid_propagate(0)\n",
    "Frame1.grid(row=0)    \n",
    "\n",
    "Frame2 = tk.Frame(win, width=570, height=600, bg='white')\n",
    "Frame2.grid_propagate(0)\n",
    "Frame2.grid(row=1, sticky = tk.W)\n",
    "\n",
    "Frame3 = tk.Frame(win, width=160, height=600, bg='white')\n",
    "Frame3.grid_propagate(0)\n",
    "Frame3.grid(row=1)    \n",
    "\n",
    "Frame4 = tk.Frame(win, width=570, height=600, bg='white')\n",
    "Frame4.grid_propagate(0)\n",
    "Frame4.grid(row=1, sticky=tk.E)    \n",
    "\n",
    "Frame5 = tk.Frame(win, width=1300, height=20, bg='black')\n",
    "Frame5.grid_propagate(0)\n",
    "Frame5.grid(row=2, sticky=tk.S)    \n",
    "\n",
    "\n",
    "user_text = scrolledtext.ScrolledText(Frame2, width=68, height=37, wrap=tk.WORD, relief='solid')\n",
    "user_text.grid(column=0, row=0, columnspan=3, padx=(5,5))\n",
    "\n",
    "output = scrolledtext.ScrolledText(Frame4, width=68, height=37, wrap=tk.WORD, relief='solid')\n",
    "output.grid(column=0, row=0, columnspan=3, padx=(5,5))\n",
    "\n",
    "def openFile():\n",
    "    global filename\n",
    "    filename = askopenfilename()  \n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(filename) as f:\n",
    "            text = f.read()\n",
    "            user_text.insert(tk.INSERT, text)\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        import PyPDF2\n",
    "         # creating a pdf file object\n",
    "        pdfFileObj = open(filename, 'rb')\n",
    "        # creating a pdf reader object\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        # printing number of pages in pdf file\n",
    "        pages = pdfReader.numPages\n",
    "        num = 0\n",
    "        while num <= pages:\n",
    "            print(num)\n",
    "            pageObj = pdfReader.getPage(num)\n",
    "            user_text.insert(tk.INSERT, pageObj.extractText())\n",
    "            print(pageObj.extractText())\n",
    "            num+=1\n",
    "            if num == pages:\n",
    "                pdfFileObj.close()\n",
    "                break\n",
    "   # elif filename.endswith((\"doc\", \"docx\")):\n",
    "        \n",
    "def clear_text():\n",
    "    user_text.delete(\"1.0\", \"end\")\n",
    "    output.delete(\"1.0\", \"end\")\n",
    "    \n",
    "def summarize():\n",
    "    text=user_text.get(\"1.0\",\"end\")\n",
    "    print(text)\n",
    "    a = generate_summary(text, top_n=5)\n",
    "    output.insert(tk.INSERT, a)\n",
    "\n",
    "def extract_keywords():\n",
    "    text = user_text.get(\"1.0\", \"end\")\n",
    "    b = \"\\n *****************************KEYWORDS*************************** \\n\" + str(extract(top_n=10, nr_candidates=20, doc=text)) + \"\\n\"\n",
    "    output.insert(tk.INSERT, b)\n",
    "\n",
    "#Import\n",
    "image0 = Image.open(\"button_import.png\")\n",
    "image0 = image0.resize((140, 45))\n",
    "click_btn0 = ImageTk.PhotoImage(image0)\n",
    "img_label0= tk.Label(image=click_btn0)\n",
    "import_= tk.Button(Frame3, image=click_btn0, borderwidth=0, command=openFile)\n",
    "import_.grid(column=0, row=0, pady=(0,50), padx=(10,0))\n",
    "\n",
    "#Summarize Button\n",
    "image = Image.open(\"button_summarize.png\")\n",
    "image = image.resize((140, 45))\n",
    "click_btn = ImageTk.PhotoImage(image)\n",
    "img_label= tk.Label(image=click_btn)\n",
    "summarize= tk.Button(Frame3, image=click_btn, borderwidth=0, command=summarize)\n",
    "summarize.grid(column=0, row=0, pady=(80,0), padx=(10,0))\n",
    "#summarize = tk.Button(Frame3, height=10, width=40, text =\"Hello\", image=photo)\n",
    "\n",
    "#Extract Keywords\n",
    "image2 = Image.open(\"button_extract-keywords.png\")\n",
    "image2 = image2.resize((140, 45))\n",
    "click_btn2 = ImageTk.PhotoImage(image2)\n",
    "img_label2= tk.Label(image=click_btn2)\n",
    "extract_keywords= tk.Button(Frame3, image=click_btn2, borderwidth=0, command=extract_keywords)\n",
    "extract_keywords.grid(column=0, row=0, pady=(200,0), padx=(10,0))\n",
    "\n",
    "#Clear\n",
    "image3 = Image.open(\"button_clear.png\")\n",
    "image3 = image3.resize((140, 45))\n",
    "click_btn3 = ImageTk.PhotoImage(image3)\n",
    "img_label3= tk.Label(image=click_btn3)\n",
    "clear= tk.Button(Frame3, image=click_btn3, borderwidth=0, command=clear_text)\n",
    "clear.grid(column=0, row=0, pady=(317,0), padx=(10,0))\n",
    "\n",
    "\n",
    "\n",
    "# Making the text read only\n",
    "\n",
    "tk.Label(Frame5, text=\"Designed with love by: \", font=font2, bg='black', fg='white').grid(column=0, row=1, padx=(600,0), pady=(2,0))\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 437, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\http\\client.py\", line 458, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\http\\client.py\", line 502, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 228, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 182, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 323, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 183, in resolve\n",
      "    discovered_reqs.extend(self._resolve_one(requirement_set, req))\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 388, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 340, in _get_abstract_dist_for\n",
      "    abstract_dist = self.preparer.prepare_linked_requirement(req)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 467, in prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 255, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 129, in get_http_url\n",
      "    from_path, content_type = _download_http_url(\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 282, in _download_http_url\n",
      "    for chunk in download.chunks:\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 168, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 64, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\Dee\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 442, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
      "Building wheels for collected packages: PyPDF2\n",
      "  Building wheel for PyPDF2 (setup.py): started\n",
      "  Building wheel for PyPDF2 (setup.py): finished with status 'done'\n",
      "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61087 sha256=6a430eab3ce88ee22d9e1ec996ccb5e1e3ae8732e2f97105cfaa11232b0be126\n",
      "  Stored in directory: c:\\users\\dee\\appdata\\local\\pip\\cache\\wheels\\b1\\1a\\8f\\a4c34be976825a2f7948d0fa40907598d69834f8ab5889de11\n",
      "Successfully built PyPDF2\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-1.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "NAME\n",
      " \n",
      "ISHOLA FOLUKE RACHEAL\n",
      " \n",
      " \n",
      "MATRIC NUMBER\n",
      " \n",
      "17/77JD085\n",
      " \n",
      " \n",
      "DEPARTMENT\n",
      " \n",
      "SOCIOLOGY\n",
      " \n",
      " \n",
      "COURSE\n",
      " \n",
      "SOC \n",
      "407\n",
      " \n",
      " \n",
      "COURSE TITLE\n",
      " \n",
      "URBANIZATION AND LABOUR MIGRATION 1\n",
      " \n",
      " \n",
      "LECTURER IN CHARGE\n",
      " \n",
      "DR RAJI\n",
      " \n",
      " \n",
      "ASSIGNMENT\n",
      " \n",
      "DISCUSS IN DETAILS THE POSITIVE EFFECTS OF MIGRATION ON THE PLACE OF \n",
      "ORIGIN.\n",
      " \n",
      "\n",
      "1\n",
      "I\n",
      "SHOLA FOLUKE RACHEAL\n",
      " \n",
      " \n",
      "17/77JD085\n",
      " \n",
      "ISHOLA FOLUKE R\n",
      "ACHEAL\n",
      " \n",
      " \n",
      "17/77JD085\n",
      " \n",
      "Migration decisions are influenced by d\n",
      "iffering factors\n",
      " \n",
      "that \"push\" migrants away from their home \n",
      "areas and \"pull\" them toward the receiving areas. It is possible that these differences are \n",
      "economically related. Such include variations in income and educational opportunity; political \n",
      "differences in\n",
      " \n",
      "religious freedom; or family differences in geographic location.\n",
      " \n",
      "Individuals' inclination to migrate is influenced by a variety of factors, some of which are favorable, \n",
      "such as differentials in wages or returns to migration. Among these include transporta\n",
      "tion expenses, \n",
      "the effort expended in seeking for accommodation and jobs in the new area, as well as \n",
      "\"psychological\" costs, a term economists use to describe costs that are not monetary but \n",
      "nonetheless function as barriers to migration, such as the separat\n",
      "ion from family members. It is \n",
      "found that the distance between the sending and receiving countries increases the cost of migration \n",
      "(due to increased transportation costs), whereas the presence of established migrant networks in \n",
      "the receiving region reduces\n",
      " \n",
      "the cost of migration. The information provided by these networks of \n",
      "prior immigrants with comparable ethnic or national backgrounds about job contacts and \n",
      "accommodation is invaluable.\n",
      " \n",
      "Economic migration and personal migration a\n",
      "re two very different types of movement that are \n",
      "often confused. Temporary migrants are those who will return to their place of origin at some time, \n",
      "but their stay can last from months to years. A contract worker or a guest worker are examples of \n",
      "temporary\n",
      " \n",
      "migrants. Individuals who hold special permits that allow them to cross an international \n",
      "border daily, weekly, or even monthly to work in another country are also included in this category. \n",
      "Some refugees and political asylum seekers are only there for a s\n",
      "hort period of time; these \n",
      "individuals intend to return to their home countries once they are no longer persecuted. Due to the \n",
      "fact that most foreign students return to their home countries after completing their studies, many \n",
      "international students are al\n",
      "so transitory migrants. However, family reunion migration tends to be \n",
      "permanent.\n",
      " \n",
      "A large portion of migration is unlawful as well. Undocumented immigrants either enter the \n",
      "receiving country illegally by crossing the border covertly or arrive legitimately a\n",
      "nd overstay their \n",
      "visas. As a result of illegal immigration \n",
      "measuring\n",
      " \n",
      "migrant flows in some nations (such as the \n",
      "United States) is plagued with inaccuracies.\n",
      " \n",
      "\n",
      "2\n",
      "I\n",
      "SHOLA FOLUKE RACHEAL\n",
      " \n",
      " \n",
      "17/77JD085\n",
      " \n",
      "ISHOLA FOLUKE R\n",
      "ACHEAL\n",
      " \n",
      " \n",
      "17/77JD085\n",
      " \n",
      "Immigration and emigration policies at the country of origin and destination determine the size, \n",
      "d\n",
      "emographic, and socio\n",
      "-\n",
      "economic makeup of migratory movements, as well as the size and \n",
      "composition of the stock of foreign residents in the receiving country. This may be seen in both \n",
      "the United States and European experiences, respectively.\n",
      " \n",
      "(Asch & Reichman, 1994)\n",
      ".\n",
      " \n",
      "International\n",
      " \n",
      "migrants maintain ties to their coun\n",
      "tries of origin in a variety of different \n",
      "ways. In many cases, international migrants leave their family members behind in the country of \n",
      "origin because it is prohibitively expensive for the entire family to relocate, or because of \n",
      "restrictive immigration \n",
      "policies and uncertain conditions in the countries to which they are \n",
      "relocating to. Money sent home by migrants (referred to as remittances) has the effect of increasing \n",
      "consumption and improving the living conditions of those who have remained behind in t\n",
      "heir home \n",
      "countries. At the same time, migration causes disruptions in family life, which may have negative \n",
      "consequences for the well\n",
      "-\n",
      "being of migrant\n",
      "-\n",
      "sending households who reside in their countries of \n",
      "departure. \n",
      " \n",
      "Nikolova, Graham, and Ivlevs (2018) found\n",
      " \n",
      "that having family members abroad is associated with \n",
      "higher levels of life satisfaction and a positive effect on those who are left behind, and receiving \n",
      "remittances is associated with even greater increases in life satisfaction, particularly in poorer \n",
      "co\n",
      "ntexts both across and within countries. As a result of rising living standards or the different \n",
      "social standing that remittance\n",
      "-\n",
      "receiving families may enjoy in the community, this is likely to be \n",
      "the case. There is approximately the same amount of additio\n",
      "nal well\n",
      "-\n",
      "being influence associated \n",
      "with having relatives living abroad as there is from remittances. In this case, it is possible that \n",
      "those who remain behind derive satisfaction or joy from the knowledge that their family members \n",
      "have achieved success in\n",
      " \n",
      "a foreign country. In addition, having a family member who lives in a \n",
      "different country may increase the likelihood of the left\n",
      "-\n",
      "behinds moving abroad in the future.\n",
      " \n",
      "Some of the positive consequences of immigration on the home country are addressed below, \n",
      "using the US\n",
      "-\n",
      "Mexico immigration scenario as a typical case study.\n",
      " \n",
      "\n",
      " \n",
      "The Number of People Who Can Immigrate Has Increased\n",
      " \n",
      "The first and most signifi\n",
      "cant effect is the process of social network growth that has occurred in \n",
      "both countries as a result of the process. Masey and Espana (1987) conducted an investigation \n",
      "into the development of social networks that have resulted from Mexican immigration to th\n",
      "e \n",
      "\n",
      "3\n",
      "I\n",
      "SHOLA FOLUKE RACHEAL\n",
      " \n",
      " \n",
      "17/77JD085\n",
      " \n",
      "ISHOLA FOLUKE R\n",
      "ACHEAL\n",
      " \n",
      " \n",
      "17/77JD085\n",
      " \n",
      "United States. They came to the conclusion that social networks lower the cost of migration for \n",
      "other groups of non\n",
      "-\n",
      "migrants, thereby inducing them to migrate and thus perpetuating the \n",
      "process of migration. Migration, when combined with ties to the natio\n",
      "n of origin, promotes \n",
      "subsequent migration, and this process continues regardless of the factors that triggered\n",
      " \n",
      "the first \n",
      "migratory movements.\n",
      " \n",
      "Migration, on the other hand, becomes less expensive as community migrant networks develop \n",
      "in size, and the impo\n",
      "verished are more likely to migrate as a result. Moreover, because migrant \n",
      "households grow wealthier as a result of revenue generated overseas, big migrant networks are \n",
      "able to distribute the benefits of migration to members who are at or near the bottom o\n",
      "f the \n",
      "income and consumption distributions. As a\n",
      " \n",
      "result, inequality is reduced.\n",
      " \n",
      "\n",
      " \n",
      "While Skill\n",
      "-\n",
      "Group Members Leave, Wages at Home Rise as a Result\n",
      " \n",
      "In addition to the direct income effects of migration due to profits earned abroad, migration has \n",
      "other effect\n",
      "s on inequality due to externalities that are not directly related to the income \n",
      "consequences of migration. The decrease in the number of Mexican employees in a skill group as \n",
      "a result of migration, for example, has been shown to increase the average salar\n",
      "ies in that skill \n",
      "group. The scarcity of competent people in the home nation eventually causes the demand for the \n",
      "skill group to skyrocket, and in an effort to entice the few qualified individuals who stay, pay are \n",
      "likewise dramatically increased to attrac\n",
      "t them. The impacts of salary increases are visible in the \n",
      "living conditions of the home nation, w\n",
      "here the standard of living greatly improves\n",
      " \n",
      "and access to \n",
      "prev\n",
      "iously denied opportunities \n",
      "become\n",
      "s\n",
      " \n",
      "a reality for the majority of the population.\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing required modules\n",
    "\n",
    "import PyPDF2\n",
    " \n",
    "# creating a pdf file object\n",
    "\n",
    "pdfFileObj = open('pdftrial3.pdf', 'rb')\n",
    " \n",
    "# creating a pdf reader object\n",
    "\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    " \n",
    "# printing number of pages in pdf file\n",
    "\n",
    "pages = pdfReader.numPages\n",
    "num = 0\n",
    "while num <= pages:\n",
    "    print(num)\n",
    "    pageObj = pdfReader.getPage(num)\n",
    "    print(pageObj.extractText())\n",
    "    num+=1\n",
    "    if num == pages:\n",
    "        pdfFileObj.close()\n",
    "        break\n",
    "# creating a page object\n",
    "\n",
    "\n",
    " \n",
    "# extracting text from page\n",
    "\n",
    "#print(pageObj.extractText())\n",
    " \n",
    "# closing the pdf file object\n",
    "#pdfFileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
